# Active Reco
## Usefull active reconnaissance
- Gobuster (web server enumeration: *discover endpoints*)
- Nikto (web server)
- wapiti (web server) usa `wapiti -u http://target.com -f html -o report.html`
- Ports/Network Scanning:
  - nmap
  - rustscan
- ettercap
- netwox -> netwag se vuoi la gui
- traceroute/tracert *for windows* 
- ping
- netcat (`nc -l -p 123` ascolto su port 123)
- telnet
- ssh
- metasploit
- [smbclient](#smbclient)
- SQL:
    - `nmap -p <PORT> --script ms-sql-info,ms-sql-empty-password,ms-sql-brute <IP_TARGET>` *remember to use ms-sql-brute only if it is necessary*
    - `sqlmap -u "http://target.com/page.php?id=1" --dbs` *solo se db esposto tramite WEBAPP*

#### Complesse
- Nessus
- OpenVAS
- Qualys

## User Agent Switch
- estensione
- [Wannabrowser](#wannabrowser)
- [browserling.com](https://www.browserling.com/)

## Password Recovery & Enumeration
- Non sottovalutare il bottone password dimenticata: può rivelare se un account esiste o come funziona il reset

## Web Sites (Usefull in CTF)
- `curl sito | grep flag` provarlo sempre, potrebbe funzionare
- Se non trovi la risposta e hai delle richieste HTTP prova a cambiare il metodo
- Se il **check** è via **js** scarica tutta la pagina e la modifichi in locale come vuoi ( *se non riesci a modificarla live sul broser* )
- Controlla se esistono questi file:
  - **`.DS_Store`**: is a common file in some websites, I think only in Apache servers, it is connected with MAC and Storage
  - **`.htaccess`**: is a common file in a lots of websites, I think only in Apache servers
  - **`robots.txt`** Sometimes the websites contain a robots.txt file, it can be usefull for example for the SEO, in particular we could don't want to indexing our web sites.
- Cambiare `IP` di provenienza: è un *header*, tipicamente `X-Forwarded-For` o `Forwarded`
- Prova sempre a loggarti come **admin**
- python [`requests`](https://requests.readthedocs.io/en/latest/user/quickstart/) module
  - `page = requests.get('url', params={'getParam': 'val'})`
  - `page = requests.get(url, headers={'user-agent': 'my-app/0.0.1'})`
  - `page = requests.post('http://web-08.challs.olicyber.it/login', data={"username": "admin","password": "admin"})`
  - ```python
    data = {
    "username": "panino12345678",
    "password": "panino12345678",
    "invite": code
    }

    page = requests.post(url, json=data)
    ```
- [`beautifulSoup`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

  **Gli attributi degli elementi si accedono tramite array associativi: `soup.img['src']`**

  ```python
  import requests as req
  from bs4 import BeautifulSoup
   
  page = req.get('http://captcha.challs.olicyber.it/')
   
  soup = BeautifulSoup(page.text, 'html.parser')
  ```


